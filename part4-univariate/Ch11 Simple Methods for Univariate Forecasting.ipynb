{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3 Develop a Grid Search Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10  20  30  40  50  60  70  80  90 100]\n",
      "100\n",
      "90\n",
      "80\n",
      "70\n",
      "60\n",
      "50\n",
      "40\n",
      "30\n",
      "20\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# one step naive forecast\n",
    "def naive_forecast(history, n):\n",
    "    return(history[-n])\n",
    "\n",
    "# define dataset\n",
    "dataset = np.arange(10, 110, 10)\n",
    "print(dataset)\n",
    "#\n",
    "for i in range(1, dataset.shape[0]+1):\n",
    "    print(naive_forecast(dataset, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average forecast() function below implements this taking the historical data and a\n",
    "config array or tuple that specifies the number of prior values to average as an integer, and a string that describe the way to calculate the average (mean or median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "## history = [100]\n",
      "1 100.0\n",
      "## history = [ 90 100]\n",
      "2 95.0\n",
      "## history = [ 80  90 100]\n",
      "3 90.0\n",
      "## history = [ 70  80  90 100]\n",
      "4 85.0\n",
      "## history = [ 60  70  80  90 100]\n",
      "5 80.0\n",
      "## history = [ 50  60  70  80  90 100]\n",
      "6 75.0\n",
      "## history = [ 40  50  60  70  80  90 100]\n",
      "7 70.0\n",
      "## history = [ 30  40  50  60  70  80  90 100]\n",
      "8 65.0\n",
      "## history = [ 20  30  40  50  60  70  80  90 100]\n",
      "9 60.0\n",
      "## history = [ 10  20  30  40  50  60  70  80  90 100]\n",
      "10 55.0\n"
     ]
    }
   ],
   "source": [
    "def average_forecast(history, config):\n",
    "    n, avg_type = config\n",
    "    print('## history = {}'.format(history[-n:]))\n",
    "    # mean\n",
    "    if avg_type == 'mean':\n",
    "        return(np.average(history[-n:]))\n",
    "    if avg_type == 'median':\n",
    "        return(np.median(history[-n:]))\n",
    "\n",
    "print(dataset.shape[0])\n",
    "for i in range(1, dataset.shape[0]+1):\n",
    "    print(i, average_forecast(dataset, (i, 'mean')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30 10 20 30 10 20 30]\n",
      "negative position : -2\n",
      "mean component values = [20]\n",
      "20.0\n",
      "negative position : -2\n",
      "negative position : -4\n",
      "mean component values = [20, 30]\n",
      "25.0\n",
      "negative position : -2\n",
      "negative position : -4\n",
      "negative position : -6\n",
      "mean component values = [20, 30, 10]\n",
      "20.0\n"
     ]
    }
   ],
   "source": [
    "# one step average forecast\n",
    "def average_forecast1(history, config):\n",
    "    n, offset, avg_type = config\n",
    "    values = list()\n",
    "    if offset == 1:\n",
    "        values = history[-n:]\n",
    "    else:\n",
    "        # skip bad config\n",
    "        if n*offset > history.shape[0]:\n",
    "            raise Exception('Config beyond end of data: {} {}'.format(n,offset))\n",
    "        # try and collect n values using offset\n",
    "        for i in range(1, n+1):\n",
    "            ix = i * offset\n",
    "            print('negative position : {}'.format(-ix))\n",
    "            values.append(history[-ix])\n",
    "    # mean of last n values\n",
    "    print('{} component values = {}'.format(avg_type, values))\n",
    "    if avg_type == 'mean':\n",
    "        return np.mean(values)\n",
    "    if avg_type == 'median':\n",
    "        return np.median(values)\n",
    "    \n",
    "#\n",
    "data = np.array([10, 20, 30, 10, 20, 30, 10, 20, 30])\n",
    "print(data)\n",
    "# test naive forecast\n",
    "for i in [1, 2, 3]:\n",
    "    # i = number of elements picked from the dataset\n",
    "    print(average_forecast1(data, (i, 2, 'mean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is possible to combine both the naive and the average forecast strategies together into\n",
    "the same function.\n",
    "- There is a little overlap between the methods, specifically the n-offset into the history that is used to either persist values or determine the number of values to average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one step average forecast\n",
    "def simple_forecast1(history, config):\n",
    "    n, offset, avg_type = config\n",
    "    # if persist value, ignore other config\n",
    "    if avg_type == 'persist':\n",
    "        return history[-n]\n",
    "    # collect values to average\n",
    "    values = list()\n",
    "    if offset == 1:\n",
    "        values = history[-n:]\n",
    "    else:\n",
    "        # skip bad config\n",
    "        if n*offset > history.shape[0]:\n",
    "            raise Exception('Config beyond end of data: {} {}'.format(n,offset))\n",
    "        # try and collect n values using offset\n",
    "        for i in range(1, n+1):\n",
    "            ix = i * offset\n",
    "            print('negative position : {}'.format(-ix))\n",
    "            values.append(history[-ix])\n",
    "    # mean of last n values\n",
    "    print('{} subprocess values = {}'.format(avg_type, values))\n",
    "    if avg_type == 'mean':\n",
    "        return np.mean(values)\n",
    "    return np.median(values)\n",
    "\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "def measure_rmse(actual, predicted):\n",
    "    return np.sqrt(mean_squared_error(actual, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30 40 50 60 70] [ 80  90 100]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[:-3], dataset[-3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can now implement the walk-forward validation scheme. \n",
    "- This is a standard approach to evaluating a time series forecasting model that respects the temporal ordering of observations. \n",
    "- First, a provided univariate time series dataset is split into train and test sets using the train test split() function. \n",
    "- Then the number of observations in the test set are enumerated. \n",
    "- For each we fit a model on all of the history and make a one step forecast. \n",
    "- The true observation for the time step is then added to the history, and the process is repeated.\n",
    "- The simple forecast() function is called in order to fit a model and make a prediction. \n",
    "- Finally, an error score is calculated by comparing all one-step forecasts to the actual test set by calling the measure rmse() function. \n",
    "- The walk forward validation() function below implements this, taking a univariate time series, a number of time steps to use in the test set, and an array of model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    prediction = list()\n",
    "    # split dataset\n",
    "    X_train, X_test = train_test_split(data, n_test)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in X_train]\n",
    "    # step over each time stpe in the test set\n",
    "    for i in range(len(X_test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat = simple_forecast1(history, cfg)\n",
    "        # fit model and make forecast for history\n",
    "        prediction.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(X_test[i])\n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(X_test, prediction)\n",
    "    return error\n",
    "\n",
    "def score_model(data, n_test, cfg, debug=True):\n",
    "    result = None\n",
    "    # convert config to key\n",
    "    key = str(cfg)\n",
    "    # show all warnings and fail on exception if debugging\n",
    "    if debug:\n",
    "        result = walk_forward_validation(data, n_test, cfg)\n",
    "    else:\n",
    "        # one failure during model validation suggests an unstable config\n",
    "        try:\n",
    "            # never show warnings when grid searching, too noisy\n",
    "            with catch_warnings():\n",
    "                filterwarnings('ignore')\n",
    "                result = walk_forward_validation(data, n_test, cfg)\n",
    "        except:\n",
    "            error = None\n",
    "    if result is not None:\n",
    "        print(' > Model {} rmse error {}'.format(key, result))\n",
    "    return (key, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a set of simple configs to try\n",
    "def simple_configs(max_length, offsets=[1]):\n",
    "    configs = list()\n",
    "    for i in range(1, max_length+1):\n",
    "        for o in offsets:\n",
    "            for t in ['persist', 'mean', 'median']:\n",
    "                cfg = [i, o, t]\n",
    "                configs.append(cfg)\n",
    "    return configs\n",
    "\n",
    "def grid_search(data, cfg_list, n_test, parallel=False):\n",
    "    scores = None\n",
    "    if parallel:\n",
    "        cpu = cpu_count()\n",
    "        cpu = 3\n",
    "        print('cpu_count {}'.format(cpu))\n",
    "        executor = Parallel(n_jobs=cpu, backend='multiprocessing')\n",
    "        tasks = (delayed(score_model)(data, n_test, cfg) for cfg in cfg_list)\n",
    "        scores = executor(tasks)\n",
    "    else:\n",
    "        scores = [score_model(data, n_test, cfg) for cfg in cfg_list]\n",
    "    # remove empty results\n",
    "    scores = [s for s in scores if s != None]\n",
    "    # sort scores\n",
    "    scores.sort(key=lambda tup: tup[1])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 'persist'], [1, 1, 'mean'], [1, 1, 'median'], [2, 1, 'persist'], [2, 1, 'mean'], [2, 1, 'median'], [3, 1, 'persist'], [3, 1, 'mean'], [3, 1, 'median'], [4, 1, 'persist'], [4, 1, 'mean'], [4, 1, 'median'], [5, 1, 'persist'], [5, 1, 'mean'], [5, 1, 'median'], [6, 1, 'persist'], [6, 1, 'mean'], [6, 1, 'median']]\n"
     ]
    }
   ],
   "source": [
    "data = [10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0]\n",
    "n_test = 4\n",
    "max_length = len(data) - n_test\n",
    "cfg_list = simple_configs(max_length)\n",
    "print(cfg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Model [1, 1, 'persist'] rmse error 10.0\n",
      "mean subprocess values = [60.0]\n",
      "mean subprocess values = [70.0]\n",
      "mean subprocess values = [80.0]\n",
      "mean subprocess values = [90.0]\n",
      " > Model [1, 1, 'mean'] rmse error 10.0\n",
      "median subprocess values = [60.0]\n",
      "median subprocess values = [70.0]\n",
      "median subprocess values = [80.0]\n",
      "median subprocess values = [90.0]\n",
      " > Model [1, 1, 'median'] rmse error 10.0\n",
      " > Model [2, 1, 'persist'] rmse error 20.0\n",
      "mean subprocess values = [50.0, 60.0]\n",
      "mean subprocess values = [60.0, 70.0]\n",
      "mean subprocess values = [70.0, 80.0]\n",
      "mean subprocess values = [80.0, 90.0]\n",
      " > Model [2, 1, 'mean'] rmse error 15.0\n",
      "median subprocess values = [50.0, 60.0]\n",
      "median subprocess values = [60.0, 70.0]\n",
      "median subprocess values = [70.0, 80.0]\n",
      "median subprocess values = [80.0, 90.0]\n",
      " > Model [2, 1, 'median'] rmse error 15.0\n",
      " > Model [3, 1, 'persist'] rmse error 30.0\n",
      "mean subprocess values = [40.0, 50.0, 60.0]\n",
      "mean subprocess values = [50.0, 60.0, 70.0]\n",
      "mean subprocess values = [60.0, 70.0, 80.0]\n",
      "mean subprocess values = [70.0, 80.0, 90.0]\n",
      " > Model [3, 1, 'mean'] rmse error 20.0\n",
      "median subprocess values = [40.0, 50.0, 60.0]\n",
      "median subprocess values = [50.0, 60.0, 70.0]\n",
      "median subprocess values = [60.0, 70.0, 80.0]\n",
      "median subprocess values = [70.0, 80.0, 90.0]\n",
      " > Model [3, 1, 'median'] rmse error 20.0\n",
      " > Model [4, 1, 'persist'] rmse error 40.0\n",
      "mean subprocess values = [30.0, 40.0, 50.0, 60.0]\n",
      "mean subprocess values = [40.0, 50.0, 60.0, 70.0]\n",
      "mean subprocess values = [50.0, 60.0, 70.0, 80.0]\n",
      "mean subprocess values = [60.0, 70.0, 80.0, 90.0]\n",
      " > Model [4, 1, 'mean'] rmse error 25.0\n",
      "median subprocess values = [30.0, 40.0, 50.0, 60.0]\n",
      "median subprocess values = [40.0, 50.0, 60.0, 70.0]\n",
      "median subprocess values = [50.0, 60.0, 70.0, 80.0]\n",
      "median subprocess values = [60.0, 70.0, 80.0, 90.0]\n",
      " > Model [4, 1, 'median'] rmse error 25.0\n",
      " > Model [5, 1, 'persist'] rmse error 50.0\n",
      "mean subprocess values = [20.0, 30.0, 40.0, 50.0, 60.0]\n",
      "mean subprocess values = [30.0, 40.0, 50.0, 60.0, 70.0]\n",
      "mean subprocess values = [40.0, 50.0, 60.0, 70.0, 80.0]\n",
      "mean subprocess values = [50.0, 60.0, 70.0, 80.0, 90.0]\n",
      " > Model [5, 1, 'mean'] rmse error 30.0\n",
      "median subprocess values = [20.0, 30.0, 40.0, 50.0, 60.0]\n",
      "median subprocess values = [30.0, 40.0, 50.0, 60.0, 70.0]\n",
      "median subprocess values = [40.0, 50.0, 60.0, 70.0, 80.0]\n",
      "median subprocess values = [50.0, 60.0, 70.0, 80.0, 90.0]\n",
      " > Model [5, 1, 'median'] rmse error 30.0\n",
      " > Model [6, 1, 'persist'] rmse error 60.0\n",
      "mean subprocess values = [10.0, 20.0, 30.0, 40.0, 50.0, 60.0]\n",
      "mean subprocess values = [20.0, 30.0, 40.0, 50.0, 60.0, 70.0]\n",
      "mean subprocess values = [30.0, 40.0, 50.0, 60.0, 70.0, 80.0]\n",
      "mean subprocess values = [40.0, 50.0, 60.0, 70.0, 80.0, 90.0]\n",
      " > Model [6, 1, 'mean'] rmse error 35.0\n",
      "median subprocess values = [10.0, 20.0, 30.0, 40.0, 50.0, 60.0]\n",
      "median subprocess values = [20.0, 30.0, 40.0, 50.0, 60.0, 70.0]\n",
      "median subprocess values = [30.0, 40.0, 50.0, 60.0, 70.0, 80.0]\n",
      "median subprocess values = [40.0, 50.0, 60.0, 70.0, 80.0, 90.0]\n",
      " > Model [6, 1, 'median'] rmse error 35.0\n",
      "CPU times: user 32.1 ms, sys: 9.63 ms, total: 41.7 ms\n",
      "Wall time: 30 ms\n",
      " done\n",
      "[1, 1, 'persist'] 10.0\n",
      "[1, 1, 'mean'] 10.0\n",
      "[1, 1, 'median'] 10.0\n"
     ]
    }
   ],
   "source": [
    "%time scores = grid_search(data, cfg_list, n_test, parallel=False)\n",
    "print(' done' ) # list top 3 configs \n",
    "for cfg, error in scores[:3]:\n",
    "    print(cfg, error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu_count 3\n",
      "mean subprocess values = [60.0]\n",
      " > Model [1, 1, 'persist'] rmse error 10.0\n",
      "median subprocess values = [60.0]\n",
      "mean subprocess values = [70.0]\n",
      "median subprocess values = [70.0]\n",
      "mean subprocess values = [80.0]\n",
      "median subprocess values = [80.0]\n",
      " > Model [2, 1, 'persist'] rmse error 20.0\n",
      "mean subprocess values = [90.0]\n",
      "median subprocess values = [90.0]\n",
      "mean subprocess values = [50.0, 60.0]\n",
      " > Model [1, 1, 'mean'] rmse error 10.0\n",
      " > Model [1, 1, 'median'] rmse error 10.0\n",
      "mean subprocess values = [60.0, 70.0]\n",
      "median subprocess values = [50.0, 60.0]\n",
      " > Model [3, 1, 'persist'] rmse error 30.0\n",
      "mean subprocess values = [70.0, 80.0]\n",
      "mean subprocess values = [40.0, 50.0, 60.0]\n",
      "median subprocess values = [60.0, 70.0]\n",
      "mean subprocess values = [80.0, 90.0]\n",
      "mean subprocess values = [50.0, 60.0, 70.0]\n",
      "median subprocess values = [70.0, 80.0]\n",
      " > Model [2, 1, 'mean'] rmse error 15.0\n",
      "mean subprocess values = [60.0, 70.0, 80.0]\n",
      "median subprocess values = [80.0, 90.0]\n",
      "mean subprocess values = [70.0, 80.0, 90.0]\n",
      " > Model [3, 1, 'mean'] rmse error 20.0\n",
      " > Model [2, 1, 'median'] rmse error 15.0\n",
      "median subprocess values = [40.0, 50.0, 60.0]\n",
      "median subprocess values = [50.0, 60.0, 70.0]\n",
      "median subprocess values = [60.0, 70.0, 80.0]\n",
      "median subprocess values = [70.0, 80.0, 90.0]\n",
      " > Model [3, 1, 'median'] rmse error 20.0\n",
      " > Model [4, 1, 'persist'] rmse error 40.0\n",
      "mean subprocess values = [30.0, 40.0, 50.0, 60.0]\n",
      "mean subprocess values = [40.0, 50.0, 60.0, 70.0]\n",
      "mean subprocess values = [50.0, 60.0, 70.0, 80.0]\n",
      "mean subprocess values = [60.0, 70.0, 80.0, 90.0]\n",
      " > Model [4, 1, 'mean'] rmse error 25.0\n",
      "median subprocess values = [30.0, 40.0, 50.0, 60.0]\n",
      "median subprocess values = [40.0, 50.0, 60.0, 70.0]\n",
      "median subprocess values = [50.0, 60.0, 70.0, 80.0]\n",
      "median subprocess values = [60.0, 70.0, 80.0, 90.0]\n",
      " > Model [4, 1, 'median'] rmse error 25.0\n",
      " > Model [5, 1, 'persist'] rmse error 50.0\n",
      "mean subprocess values = [20.0, 30.0, 40.0, 50.0, 60.0]\n",
      "mean subprocess values = [30.0, 40.0, 50.0, 60.0, 70.0]\n",
      "mean subprocess values = [40.0, 50.0, 60.0, 70.0, 80.0]\n",
      "mean subprocess values = [50.0, 60.0, 70.0, 80.0, 90.0]\n",
      " > Model [5, 1, 'mean'] rmse error 30.0\n",
      "median subprocess values = [20.0, 30.0, 40.0, 50.0, 60.0]\n",
      "median subprocess values = [30.0, 40.0, 50.0, 60.0, 70.0]\n",
      "median subprocess values = [40.0, 50.0, 60.0, 70.0, 80.0]\n",
      "median subprocess values = [50.0, 60.0, 70.0, 80.0, 90.0]\n",
      " > Model [5, 1, 'median'] rmse error 30.0\n",
      " > Model [6, 1, 'persist'] rmse error 60.0\n",
      "mean subprocess values = [10.0, 20.0, 30.0, 40.0, 50.0, 60.0]\n",
      "mean subprocess values = [20.0, 30.0, 40.0, 50.0, 60.0, 70.0]\n",
      "mean subprocess values = [30.0, 40.0, 50.0, 60.0, 70.0, 80.0]\n",
      "mean subprocess values = [40.0, 50.0, 60.0, 70.0, 80.0, 90.0]\n",
      " > Model [6, 1, 'mean'] rmse error 35.0\n",
      "median subprocess values = [10.0, 20.0, 30.0, 40.0, 50.0, 60.0]\n",
      "median subprocess values = [20.0, 30.0, 40.0, 50.0, 60.0, 70.0]\n",
      "median subprocess values = [30.0, 40.0, 50.0, 60.0, 70.0, 80.0]\n",
      "median subprocess values = [40.0, 50.0, 60.0, 70.0, 80.0, 90.0]\n",
      " > Model [6, 1, 'median'] rmse error 35.0\n",
      "CPU times: user 131 ms, sys: 90.2 ms, total: 222 ms\n",
      "Wall time: 381 ms\n",
      " done\n",
      "[1, 1, 'persist'] 10.0\n",
      "[1, 1, 'mean'] 10.0\n",
      "[1, 1, 'median'] 10.0\n"
     ]
    }
   ],
   "source": [
    "%time scores = grid_search(data, cfg_list, n_test, parallel=True)\n",
    "print(' done' ) # list top 3 configs \n",
    "for cfg, error in scores[:3]:\n",
    "    print(cfg, error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
